{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Self Explaining Structures Improve NLP Models: Reproducibility Study\n",
        "###Group Members: Dhyay, Brian, Rathi \n",
        "\n",
        "**README:**\n",
        "1. Save the folder submitted with this notebook on your drive. \n",
        "2. Mount your drive. \n",
        "3. The folder structure is as follows:\n",
        "- project:\n",
        "  - sst_data (SST5 Dataset)\n",
        "  - snli_1.0 (SNLI Dataset)\n",
        "  - interpretability (Extracted spans, incorrect samples for SST5)\n",
        "  - interpret_snli (Extracted spans, incorrect samples for SNLI)\n",
        "- The last two folders are populated during execution "
      ],
      "metadata": {
        "id": "pri7QywVzK4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "HNybxt1JsPVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d609f201-ba35-4310-be62-70b729621c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtz7k8YXqHc4",
        "outputId": "d1ce23b2-a625-44b4-f321-3292000652fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5sjDp6xCH2y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import RobertaModel, RobertaConfig\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from typing import List\n",
        "import os\n",
        "from functools import partial\n",
        "from transformers import RobertaTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import string\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.cuda.is_available(), \"no GPU found, in Colab go to 'Edit->Notebook settings' and choose a GPU hardware accelerator\"\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "Ncml2C7p7THR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The collate function takes in batched input ids, pads them to the maximum length, reshapes the labels and creates span indices. This data is fed into the model. "
      ],
      "metadata": {
        "id": "0AtZQgXgyuz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(data):\n",
        "\n",
        "    reformated_input = []\n",
        "    bsz = len(data)\n",
        "    batch_list = np.array(data)\n",
        "    max_len = batch_list[:,2].max()\n",
        "\n",
        "    seq_ids = torch.ones(bsz,max_len, dtype=data[0][0][0].dtype)\n",
        "    labels = torch.from_numpy(batch_list[:,1].astype(np.int64)).unsqueeze(1)\n",
        "    seq_lengths = torch.from_numpy(batch_list[:,2].astype(np.int64)).unsqueeze(1)\n",
        "    reformated_input.append(seq_ids)\n",
        "    reformated_input.append(labels)\n",
        "    reformated_input.append(seq_lengths)\n",
        "\n",
        "    for b in range(bsz):\n",
        "      for ele in range(data[b][2]):\n",
        "        reformated_input[0][b][ele] = data[b][0][ele]\n",
        "\n",
        "    start_indices = []\n",
        "    end_indices = []\n",
        "    for i in range(1, max_len - 1):\n",
        "        for j in range(i, max_len - 1):\n",
        "            start_indices.append(i)\n",
        "            end_indices.append(j)\n",
        "\n",
        "    reformated_input.append(torch.LongTensor(start_indices))\n",
        "    reformated_input.append(torch.LongTensor(end_indices))\n",
        "      \n",
        "    return reformated_input"
      ],
      "metadata": {
        "id": "DtBiuzeyM7ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is described in the class below, it consists of the following layers:\n",
        "1. Intermediate - Roberta Base Transformer\n",
        "2. SIC - Span Infor Collect Layer: FFN which performs the tanh operation\n",
        "3. Interpretation - Assigns weights to each span \n",
        "4. Output - Computes output using weighted spans"
      ],
      "metadata": {
        "id": "-CIDTSQt_97b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfExplainingModel(nn.Module):\n",
        "   def __init__(self):\n",
        "      super().__init__()\n",
        "      self.config = RobertaConfig.from_pretrained('roberta-base', output_hidden_states=False, num_labels=5)\n",
        "      self.intermediate = RobertaModel.from_pretrained('roberta-base', num_labels=5).to(device)\n",
        "      self.sic_w1 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
        "      self.sic_w2 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
        "      self.sic_w3 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
        "      self.sic_w4 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
        "      self.interpretation = nn.Linear(self.config.hidden_size, 1)\n",
        "      self.output = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
        "   def forward(self, input, start, end):\n",
        "      mask = (input != 1).long()\n",
        "      output = self.intermediate(input, attention_mask=mask)[0]\n",
        "      output = output.to(device)\n",
        "      w1h = self.sic_w1(output)\n",
        "      w2h = self.sic_w2(output)\n",
        "      w3h = self.sic_w3(output)\n",
        "      w4h = self.sic_w4(output)\n",
        "      w1hi = torch.index_select(w1h, 1, start)\n",
        "      w2hj = torch.index_select(w2h, 1, end)\n",
        "      w3hi = torch.index_select(w3h, 1, start)\n",
        "      w3hj = torch.index_select(w3h, 1, end)\n",
        "      w4hi = torch.index_select(w4h, 1, start)\n",
        "      w4hj = torch.index_select(w4h, 1, end)\n",
        "      output = w1hi + w2hj + (w3hi - w3hj) + torch.mul(w4hi, w4hj)\n",
        "      hij = torch.tanh(output)\n",
        "      span = self.interpretation(hij).squeeze(-1)\n",
        "      aij = F.softmax(span, dim=1)\n",
        "      output = (aij.unsqueeze(-1) * hij).sum(dim = 1)\n",
        "      output = self.output(output)\n",
        "      # print(output.shape)\n",
        "      # print(output)\n",
        "      output_softmax = F.softmax(output, dim=1)\n",
        "      # print(output_softmax.shape)\n",
        "      # print(output_softmax)\n",
        "      return output, output_softmax, aij\n"
      ],
      "metadata": {
        "id": "FMbthk246RXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SST Dataset Class"
      ],
      "metadata": {
        "id": "e2MUoJxvAyJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, tokenizer):\n",
        "    text = text.strip()\n",
        "    if text[-1] == \".\":\n",
        "        text = text[:-1]\n",
        "    text = tokenizer.encode(text, add_special_tokens=False)\n",
        "    text = text[:510]\n",
        "    return text"
      ],
      "metadata": {
        "id": "8OIoAYUdW5GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SSTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, mode):\n",
        "        super().__init__()\n",
        "        self.max_length = 512\n",
        "        with open(path + mode + '.txt', 'r', encoding='utf8') as f:\n",
        "            self.data = f.readlines()\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        data = self.data[ind]\n",
        "        label, input = data.split('\\t', 1)\n",
        "        input = preprocess(input, self.tokenizer)\n",
        "        length = torch.LongTensor([len(input) + 2])\n",
        "        input = torch.LongTensor([0] + input + [2])\n",
        "        label = torch.LongTensor([int(label)])\n",
        "        return input, label, length"
      ],
      "metadata": {
        "id": "jWxcuPF1ODbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, epochs, reg_lambda):\n",
        "    train_loss = []\n",
        "    val_acc = []\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch: ', epoch)\n",
        "        loss = 0\n",
        "        model.train()\n",
        "        for ind, (input, label, length, start, end) in enumerate(tqdm(dataloader)):\n",
        "            model.zero_grad()\n",
        "            # optimizer.zero_grad()\n",
        "            output, output_softmax, a_ij = model(input.cuda(), start.cuda(), end.cuda())\n",
        "            output_labels = torch.argmax(output_softmax, dim=-1).cuda()\n",
        " \n",
        "            label = label.view(-1).cuda()\n",
        "            loss = criterion(output, label) - reg_lambda*a_ij.pow(2).sum(dim=1).mean()\n",
        "          \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss += loss.item()\n",
        "        # test()\n",
        "        scheduler.step()\n",
        "        model.eval()\n",
        "        _, _, _, acc, _ = test(model, valloader, isFileOutput=False)\n",
        "        print('Train loss: ', loss)\n",
        "        train_loss.append(loss.item())\n",
        "        print('Validation Acc: ', acc)\n",
        "        val_acc.append(acc.item())\n",
        "    return train_loss, val_acc\n"
      ],
      "metadata": {
        "id": "5ri93LiD6H0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSpans(input,label,length,start,end,pred,aij,k=5):\n",
        "  topkvalues, topkindices = torch.topk(aij, k)\n",
        "  spans = []\n",
        "  explainers = []\n",
        "  incorrect_labels = []\n",
        "  avg_span_length = 0\n",
        "  span_len = 0\n",
        "  c = 0\n",
        "  for i in range(input.shape[0]):\n",
        "    c += 1\n",
        "    sent_ids = input[i].tolist()\n",
        "    # print(sent_ids)\n",
        "    tok = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    sent = tok.decode(sent_ids, skip_special_tokens=True)\n",
        "    for j in range(5):\n",
        "      max_prob = topkvalues[i][j]\n",
        "      span_sent = tok.decode(sent_ids[start[topkindices[i][j]]:end[topkindices[i][j]]+1],skip_special_tokens=True)\n",
        "      sent_before_span = tok.decode(sent_ids[:start[topkindices[i][j]]],skip_special_tokens=True)\n",
        "      sent_after_span = tok.decode(sent_ids[end[topkindices[i][j]]+1:],skip_special_tokens=True)\n",
        "      line0 = sent_before_span + '【' + span_sent + '】' + sent_after_span\n",
        "      explainers.append(format('%.4f' % max_prob) + \"->\" + line0 + '\\n')\n",
        "      if(j==0):\n",
        "        span_len += end[topkindices[i][j]] - start[topkindices[i][j]] + 1\n",
        "        line1 = str(label[i].item()) + '\\t' + span_sent + '\\n'\n",
        "        spans.append(line1)\n",
        "        if(pred[i] != label[i]):\n",
        "          line2 = 'Correct: ' + str(label[i].item()) + '\\t' + 'Predicted: ' + str(pred[i].item()) + '\\t' + line0 + '\\n'\n",
        "          incorrect_labels.append(line2)\n",
        "    avg_span_length = span_len/c\n",
        "  return spans, explainers, incorrect_labels, avg_span_length\n",
        "\n"
      ],
      "metadata": {
        "id": "M8GnXFji4ncm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, testloader, isFileOutput=False):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    spans_list = []\n",
        "    explainers_list = []\n",
        "    incorrect_labels_list = []\n",
        "    span_len = 0\n",
        "    c = 0\n",
        "    with torch.no_grad():\n",
        "      for ind, (input, label, length, start, end) in enumerate(tqdm(testloader)):\n",
        "          # print(input)\n",
        "          c+=1\n",
        "          output, output_softmax, aij = model(input.cuda(), start.cuda(), end.cuda())\n",
        "          # print(output_softmax)\n",
        "          label = label.reshape(output_softmax.shape[0]).cuda()\n",
        "          pred = torch.argmax(output_softmax, dim=-1)\n",
        "          if (isFileOutput):\n",
        "            spans, explainers, incorrect_labels, avg_span_length = getSpans(input,label,length,start,end,pred,aij)\n",
        "            spans_list.append(spans)\n",
        "            explainers_list.append(explainers)\n",
        "            incorrect_labels_list.append(incorrect_labels)\n",
        "            span_len += avg_span_length\n",
        "        \n",
        "          count = (pred == label).sum()\n",
        "          correct = correct + count\n",
        "    print('Accuracy: ', correct/len(testloader.dataset))\n",
        "    print('Avg span length: ', span_len/c)\n",
        "    acc = correct/len(testloader.dataset)\n",
        "    return spans_list, explainers_list, incorrect_labels_list, acc, span_len/c"
      ],
      "metadata": {
        "id": "3XWk7uju6K9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments and Training on the SST-5 Dataset"
      ],
      "metadata": {
        "id": "TdyC-jk9BTrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/project/sst_data/'\n",
        "train_iter = SSTDataset(path, mode=\"train\")\n",
        "test_iter = SSTDataset(path, mode=\"test\")\n",
        "val_iter = SSTDataset(path, mode=\"dev\")\n",
        "dataloader = DataLoader(train_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))\n",
        "testloader = DataLoader(test_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))\n",
        "valloader = DataLoader(val_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))"
      ],
      "metadata": {
        "id": "SCx23WDd5_gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "bOOh1gyewGKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SelfExplainingModel().to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "reg_lambda = 1\n",
        "num_epochs = 20\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*len(dataloader), num_training_steps=len(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ah9ILy6DHi",
        "outputId": "48af8fd0-6bec-4c98-f24f-779babde4d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_acc = train(model, dataloader, num_epochs, reg_lambda)"
      ],
      "metadata": {
        "id": "OYZEk_myDdwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model checkpoint\n",
        "EPOCH = num_epochs\n",
        "PATH = \"/content/drive/MyDrive/project/orig_train_model.pt\"\n",
        "LOSS = 1.2227 #replace with obtained loss\n",
        "\n",
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': LOSS,\n",
        "            }, PATH)"
      ],
      "metadata": {
        "id": "a8gR8njuBcUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading model checkpoint\n",
        "PATH = \"/content/drive/MyDrive/project/orig_train_model.pt\"\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "metadata": {
        "id": "3nN-PuehjGWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "spans, explainers, incorrect_labels, acc, avg_span_length = test(model, testloader, isFileOutput=True)"
      ],
      "metadata": {
        "id": "4NhhiLVUDb-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "l = [0,1,1.5,3]\n",
        "accs = [0.5447,0.5651,0.5615,0.5551]\n",
        "plt.plot(l,accs)\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dW0dDRZg7eUr",
        "outputId": "567e74c2-c65a-4e4e-f1d3-fddfc2e62f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save test spans and results\n",
        "path = '/content/drive/MyDrive/project/interpretability/'\n",
        "with open(path + 'explainers.txt', 'w', encoding='utf8') as f:\n",
        "  for item in explainers:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))\n",
        "with open(path + 'spans.txt', 'w', encoding='utf8') as f:\n",
        "  for item in spans:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))\n",
        "with open(path +  'incorrect_labels.txt', 'w', encoding='utf8') as f:\n",
        "  for item in incorrect_labels:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))"
      ],
      "metadata": {
        "id": "eQW-tnGlV7BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training on original train and testing on spans\n",
        "testspan_iter = SSTDataset(path, mode=\"spans\")\n",
        "testspan_loader = DataLoader(testspan_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))\n",
        "spans, explainers, incorrect_labels, acc, avg_span_length = test(model, testspan_loader, isFileOutput=True)"
      ],
      "metadata": {
        "id": "ZmjHcUIK2Arq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save test spans and results\n",
        "spans, explainers, incorrect_labels, acc = test(dataloader, isFileOutput=True)\n",
        "with open(path + 'train_explainers.txt', 'w', encoding='utf8') as f:\n",
        "  for item in explainers:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))\n",
        "with open(path + 'train_spans.txt', 'w', encoding='utf8') as f:\n",
        "  for item in spans:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))\n",
        "with open(path +  'train_incorrect_labels.txt', 'w', encoding='utf8') as f:\n",
        "  for item in incorrect_labels:\n",
        "    for ele in item:\n",
        "      f.write(str(ele))"
      ],
      "metadata": {
        "id": "q02qgV0A5cTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training on span train\n",
        "trainspan_iter = SSTDataset(path, mode=\"train_spans\")\n",
        "trainspan_loader = DataLoader(trainspan_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))\n",
        "train(model, trainspan_loader, num_epochs, reg_lambda)"
      ],
      "metadata": {
        "id": "zKjh5WyQCPUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = num_epochs\n",
        "PATH = \"/content/drive/MyDrive/project/span_train_model.pt\"\n",
        "LOSS = 2.6895 #change to obtained loss\n",
        "\n",
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': LOSS,\n",
        "            }, PATH)"
      ],
      "metadata": {
        "id": "28s4bX1DHImE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing on orig test\n",
        "spans, explainers, incorrect_labels, acc, avg_span_length = test(model, testloader, isFileOutput=True)"
      ],
      "metadata": {
        "id": "aH9I4xyJHyIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing on span test\n",
        "spans, explainers, incorrect_labels, acc, avg_span_length = test(testspan_loader, isFileOutput=True)"
      ],
      "metadata": {
        "id": "sD6yz5DlH4Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNLI Dataset Class"
      ],
      "metadata": {
        "id": "CVqk--QAA0_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SNLIDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, mode):\n",
        "        super().__init__()\n",
        "        self.max_length = 512\n",
        "        self.data = []\n",
        "        self.input1 = []\n",
        "        self.input2 = []\n",
        "        self.label = []\n",
        "        labels = {\"contradiction\": 0, 'neutral': 1, \"entailment\": 2}\n",
        "        with open(path + 'snli_1.0_' + mode + '.jsonl', 'r', encoding='utf8') as f:\n",
        "            self.data = [json.loads(line) for line in f]\n",
        "        for data in self.data:\n",
        "            if data['gold_label'] not in labels:\n",
        "                continue\n",
        "            self.input1.append(data['sentence1'])\n",
        "            self.input2.append(data['sentence2'])\n",
        "            self.label.append(labels[data['gold_label']])\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        in1 = self.input1[ind]\n",
        "        in2 = self.input2[ind]\n",
        "        label = self.label[ind]\n",
        "        inp = preprocess(in1, self.tokenizer) + [2] + preprocess(in2, self.tokenizer)\n",
        "        length = torch.LongTensor([len(inp) + 2])\n",
        "        input = torch.LongTensor([0] + inp + [2])\n",
        "        label = torch.LongTensor([label])\n",
        "        return input, label, length"
      ],
      "metadata": {
        "id": "YAGeP-EcuTJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/project/snli_1.0/'\n",
        "train_iter = SNLIDataset(path, mode=\"train\")\n",
        "test_iter = SNLIDataset(path, mode=\"test\")\n",
        "val_iter = SNLIDataset(path, mode=\"dev\")\n",
        "dataloader = DataLoader(train_iter, batch_size=12, shuffle=False, collate_fn=partial(collate))\n",
        "testloader = DataLoader(test_iter, batch_size=12, shuffle=False, collate_fn=partial(collate))\n",
        "valloader = DataLoader(val_iter, batch_size=12, shuffle=False, collate_fn=partial(collate))"
      ],
      "metadata": {
        "id": "N1tNQH5eDm9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SelfExplainingModel().to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "reg_lambda = 1\n",
        "num_epochs = 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*len(dataloader), num_training_steps=len(dataloader))"
      ],
      "metadata": {
        "id": "n0nJUJ90Dq_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a68fe6-ae0e-4fec-dec5-8a219355b309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_acc = train(model, dataloader, num_epochs, reg_lambda)"
      ],
      "metadata": {
        "id": "x5bqdD4LPXMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spans, explainers, incorrect_labels, acc, avg_span_length = test(model, testloader, isFileOutput=True)"
      ],
      "metadata": {
        "id": "1KcQgzJePYiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/project/interpret_snli/'\n",
        "\n",
        "with open(path + 'snli_1.0_test_explainers.jsonl', 'w', encoding='utf8') as f:\n",
        "  for item in explainers:\n",
        "    for ele in item:\n",
        "      json.dumps(ele)\n",
        "with open(path + 'snli_1.0_test_spans.jsonl', 'w', encoding='utf8') as f:\n",
        "  for item in spans:\n",
        "    for ele in item:\n",
        "      json.dumps(ele)\n",
        "with open(path +  'snli_1.0_test_incorrect_labels.jsonl', 'w', encoding='utf8') as f:\n",
        "  for item in incorrect_labels:\n",
        "    for ele in item:\n",
        "      json.dumps(ele)"
      ],
      "metadata": {
        "id": "Lnmeur42GtL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/project/interpret_snli/'\n",
        "test_spans_iter = SNLIDataset(path, mode=\"test_spans\")\n",
        "test_spans_loader = DataLoader(test_spans_iter, batch_size=10, shuffle=False, collate_fn=partial(collate))"
      ],
      "metadata": {
        "id": "nlQF9APSL8_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The other experiments for F-S, S-F and S-S can be repeated as described above for SST-5"
      ],
      "metadata": {
        "id": "aLmWx-nCHNpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}